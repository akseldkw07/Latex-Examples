\documentclass[12pt]{article}
\usepackage{amsmath, amssymb}
\usepackage[margin=0.5cm]{geometry}
\usepackage{array}
\usepackage{helvet}
\usepackage{longtable}
\usepackage{tikz-cd}
\usepackage{tikz}
\usepackage{macros}

% Add libraries for positioning and arrows
\usetikzlibrary{trees, positioning, arrows}
\usepackage{changepage} % For margin adjustments

\begin{document}

\begin{center}
		{\LARGE\bfseries Special Matrices and their Properties}\par
		\vspace{1em}
\end{center}

% Matrix Type Hierarchy Tree
\begin{center}
  \begin{tikzpicture}[
						level distance=4em, % Adjusted level distance
						every node/.style={font=\small},
						sibling distance=15em, % Adjusted sibling distance
						edge from parent/.style={draw,-latex}
				]
    \node (Matrix) {Matrix}
				child { node (Symmetric) {Symmetric}
						child { node (PSD) {PSD} [sibling distance=3em]
								child { node (Gram) {Gram ($\bX^\top\bX$)}
										child { node (Correlation) {Correlation} }
								}
								child { node [xshift=0.8cm](PD) {PD} }
						}
						child { node (Diagonal) {Diagonal}[sibling distance=8em]
								child { node [xshift=0.3cm](Identity) {Identity} }
								child { node (EigenvalueMatrix) {Eigenvalues $\Lambda$} }
						}
				}
				child { node (Invertible) {Invertible} }
				child { node [xshift=-3cm](Orthogonal) {Orthogonal}[sibling distance=8em]
						child { node [xshift=-0.5cm](LeftOrthogonal) {Left Orth $\bA^\top \bA
								= \bI$}
								child { node (Leftpseudoinverse) {$A^\dagger$: $n > d$} }
						}
						child { node [xshift=0.5cm](RightOrthogonal) {Right Orth $\bA
								\bA^\top = \bI$}
								child { node (Rightpseudoinverse) {$A^\dagger$: $n < d$} }
						}
				};
				% child { node {Skew-Symmetric} }
				% child { node {Triangular} }
				% child { node {Idempotent} };
				% child { node {Nilpotent} };

    % Add arrows for overlaps
    \draw[-latex] (Invertible) -- (PD);
    \draw[-latex] (Invertible) -- (Identity);
    \draw[-latex] (Diagonal) -- (Identity);
    \draw[-latex] (Invertible) -- (Orthogonal);

  \end{tikzpicture}
  \vspace{0.5em}
\end{center}

\begin{longtable}{|>{\bfseries}m{3.5cm}|m{5cm}|m{10.5cm}|}
		\hline
		\tbf{Term} & \tbf{Definition} & \tbf{Unique Attributes /
		Key Properties} \\
		\hline
		Diagonal & $a_{ij} = 0$ for $i \ne j$ &
		- Determinant is product of diagonal entries \newline
		- Eigenvalues are diagonal entries \newline
		- $\bA^k$ is diagonal with entries raised to $k$ \\
		\hline
		Symmetric & $\bA = \bA^T$, i.e., $a_{ij} = a_{ji}$ &
		- $\bx^T \bA \bx = (\bA \bx)^T \bx$ for all $\bx$ if $\bA$ is symmetric \newline
		- $\bv^\top \bA \bv \leq \lambda_{\max}(\bA) \|\bv\|^2$ \newline
		- All eigenvalues are real \newline
		- Eigenvectors for distinct eigenvalues are orthogonal \newline
		- Diagonalizable via orthogonal matrices \\
		\hline
		Identity ($\bI$) & $\bI_{ij} = \delta_{ij}$ &
		- $\bA\bI = \bI\bA = \bA$ \newline
		- $\bI^{-1} = \bI$ \newline
		- All eigenvalues are 1 \\
		\hline
		Invertible (Non-singular) & Exists $\bA^{-1}$ such that $\bA\bA^{-1} =
		\bA^{-1}\bA = \bI$ &
		- $\det(\bA) \ne 0$ \newline
		- Linearly independent rows and columns \newline
		- No zero eigenvalues \\
		\hline
		Singular & A square matrix with $\det(\bA) = 0$ &
		- Not invertible \newline
		- Linearly dependent rows or columns \newline
		- At least one zero eigenvalue \\
		\hline
		Orthogonal & $\bA^{-1} = \bA^T$, so $\bA^T \bA = \bI$ &
		- Rows and columns form an orthonormal set \newline
		- Preserves lengths and angles \newline
		- $\det(\bA) = \pm 1$ \\
		\hline
		Left Orthogonal & $\bA^T \bA = \bI$ (tall matrix, $n \geq d$) &
		- Columns are orthonormal \newline
		- $\bA^\dagger = \bA^T$ (left pseudoinverse) \newline
		- Used when $\bA$ has full column rank \newline
		- Condition: $\text{rank}(\bA) = d$ where $\bA \in \mathbb{R}^{n \times d}$ \\
		\hline
		Right Orthogonal & $\bA \bA^T = \bI$ (wide matrix, $n \leq d$) &
		- Rows are orthonormal \newline
		- $\bA^\dagger = \bA^T$ (right pseudoinverse) \newline
		- Used when $\bA$ has full row rank \newline
		- Condition: $\text{rank}(\bA) = n$ where $\bA \in \mathbb{R}^{n \times d}$ \\

		\hline
		Pseudoinverse (Moore--Penrose) & Generalized inverse $\bA^\dagger$
		satisfying the four Penrose conditions &
		- Always exists and is unique for any matrix \newline
		- \tbf{Full column rank} ($n \geq d$, $\text{rank}(\bA) = d$): \newline
		\quad $\bA^\dagger = (\bA^T \bA)^{-1} \bA^T$ (left pseudoinverse) \newline
		- \tbf{Full row rank} ($n \leq d$, $\text{rank}(\bA) = n$): \newline
		\quad $\bA^\dagger = \bA^T (\bA \bA^T)^{-1}$ (right pseudoinverse) \newline
		- \tbf{Square and invertible}: $\bA^\dagger = \bA^{-1}$ \newline
		- \tbf{Rank deficient}: Computed via SVD decomposition \\

		\hline
		Positive Definite & $\bx^T \bA \bx > 0$ for all non-zero $\bx$ &
		- All eigenvalues are positive \newline
		- $\det(\bA) > 0$ \newline
		- Always defines an inner product: for any PD matrix, there exists a unique inner product \newline
		- For any inner product, there exists a PD matrix $\bA$ such that $\langle \bx, \by
		\rangle = \bx^T \bA \by$ \newline
		- Invertible \\
		\hline
		Positive Semi-Definite & $\bA = \bA^T$, $\bx^T \bA \bx \ge 0$ for all $\bx$ &
		- All eigenvalues are non-negative \newline
		- $\det(\bA) \ge 0$ \newline
		- Always symmetric \newline
		- Can always be written as $\bX^T \bX$ for some $\bX$ (Gram matrix) \newline
		- Defines a semi-inner product \\
		\hline
		Triangular (Upper / Lower) &
		Upper: $a_{ij} = 0$ for $i > j$; Lower: $a_{ij} = 0$ for $i < j$ &
		- Determinant is product of diagonal entries \newline
		- Eigenvalues are diagonal entries \newline
		- Solves systems efficiently via substitution \\
		\hline
		Skew-Symmetric & $\bA = -\bA^T$, so $a_{ii} = 0$ &
		- Eigenvalues are 0 or purely imaginary \newline
		- $\bx^T \bA \bx = 0$ for all $\bx$ \\
		\hline
		Idempotent & $\bA^2 = \bA$ &
		- Used in projection operations \newline
		- Eigenvalues are 0 or 1 \\
		\hline
		Nilpotent & $\bA^k = 0$ for some $k \in \mathbb{N}$ &
		- All eigenvalues are 0 \\
		\hline
		Orthogonal Projection & Linear transformation $\bp$ where $\bp^2 = \bp$
		and $\bp = \bp^T$ &
		- Projects onto a subspace along its orthogonal complement \newline
		- Minimizes distance to the subspace (best approximation) \newline
		- $\text{Im}(\bp)$ is a subspace; $\text{Ker}(\bp) = \text{Im}(\bI - \bp)$ \\
		\hline
		Linear Map (Transformation) & Function $T: V \rightarrow W$
		satisfying $T(a\bx + b\by) = aT(\bx) + bT(\by)$ &
		- Represented by a matrix in finite dimensions \newline
		- Preserves linear structure \newline
		- Kernel and image define fundamental subspaces \\
		\hline
		Fundamental Subspaces & Column space, row space, null space, left null space &
		- Column space: span of columns (range of $\bA$) \newline
		- Row space: span of rows = col space of $\bA^T$ \newline
		- Null space: solutions to $\bA\bx = 0$ \newline
		- Left null space: null space of $\bA^T$ \\
		\hline
		Unitary & $\bU^\dagger = \bU^{-1}$, where $\bU^\dagger$ is the conjugate
		transpose of $\bU$ &
		- $\bU^\dagger \bU = \bU \bU^\dagger = \bI$ \newline
		- Preserves inner products: $\langle \bU\bx, \bU\by \rangle =
		\langle \bx, \by \rangle$ \newline
		- All eigenvalues lie on the unit circle: $|\lambda| = 1$ \newline
		- Generalization of orthogonal matrices to complex space \\
		\hline
		Gram Matrix & $\bG = \bX^T \bX$ for some matrix $\bX$ &
		- Always positive semi-definite \newline
		- Symmetric by construction \newline
		- Entries are inner products: $G_{ij} = \langle \bx_i, \bx_j \rangle$ \newline
		- Used in least squares and quadratic forms \\
		\hline
		Eigenvalue Matrix & Matrix with known eigenvalues $\lambda_1, \ldots, \lambda_n$ &
		- Can be diagonalized as $\bA = \bp\bLam \bp^{-1}$ \newline
		- $\bLam$ is diagonal matrix of eigenvalues \newline
		- $\bp$ contains corresponding eigenvectors as columns \newline
		- Powers: $\bA^k = \bp\bLam^k \bp^{-1}$ \\
		\hline
		Eigenvalue Matrix ($\bLam$) & Diagonal matrix $\bLam = \text{diag}(\lambda_1,
		\ldots, \lambda_n)$ &
		- Contains eigenvalues on the diagonal \newline
		- Result of eigendecomposition/PCA \newline
		- $\bLam_{ii} = \lambda_i$, $\bLam_{ij} = 0$ for $i \neq j$ \newline
		- Used in spectral analysis and dimensionality reduction \\
		\hline
		Covariance Matrix & $\text{Cov}(\bX) = \frac{1}{n-1}(\bX - \mu)^T(\bX - \mu)$ \newline
		(unbiased) &
		- Always positive semi-definite \newline
		- Symmetric by construction \newline
		- Diagonal entries are variances \newline
		- Off-diagonal entries are covariances \\
		\hline
		Correlation Matrix & Normalized covariance matrix with unit diagonal &
		- Positive semi-definite \newline
		- Symmetric with $\rho_{ii} = 1$ \newline
		- Entries satisfy $-1 \leq \rho_{ij} \leq 1$ \newline
		- Used in statistics and data analysis \\
		\hline
		Householder Matrix & $H = I - 2\frac{vv^T}{v^T v}$ for vector $v$ &
		- Symmetric and orthogonal \newline
		- $H^2 = I$ (involutory) \newline
		- Reflects vectors across hyperplane \newline
		- Used in QR decomposition \\
		\hline
		Permutation Matrix & Matrix with exactly one 1 in each row and column &
		- Orthogonal matrix \newline
		- Determinant is $\pm 1$ \newline
		- Reorders rows/columns when multiplied \newline
		- $P^T P = I$ and $P^{-1} = P^T$ \\
		\hline
		Circulant Matrix & Each row is cyclic shift of previous row &
		- Diagonalized by Discrete Fourier Transform \newline
		- Eigenvalues given by DFT of first row \newline
		- Used in signal processing \newline
		- Fast matrix-vector multiplication via FFT \\
		\hline
		Toeplitz Matrix & Constant along each diagonal: $a_{ij} = a_{i-j}$ &
		- Determined by $2n-1$ parameters \newline
		- Includes circulant matrices as special case \newline
		- Used in time series and signal processing \newline
		- Fast algorithms available for solving systems \\
		\hline
		Hankel Matrix & Constant along each anti-diagonal: $a_{ij} = a_{i+j}$ &
		- Symmetric if square \newline
		- Related to Toeplitz matrices \newline
		- Used in system identification \newline
		- Connection to moment problems \\
		\hline

\end{longtable}

\end{document}
